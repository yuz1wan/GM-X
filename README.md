# GM-X

[![Project Page](https://img.shields.io/badge/Project-Page-green.svg)](https://www.rhos.ai/research/gm-100)
[![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)]([YOUR_PAPER_URL](https://arxiv.org/abs/2601.11421))
[![Dataset](https://img.shields.io/badge/Dataset-Link-blue.svg)](https://huggingface.co/rhos-ai)
[![License](https://img.shields.io/badge/License-Apache%202.0-yellow.svg)](./LICENSE)


![Pipeline](./assets/pipeline.jpg)
## üöÄ Introduction
**GM-X is a research project led by [rhos.ai](https://www.rhos.ai/).**

GM-X is an ongoing research initiative designed to address the current challenges in robot learning, where task structure often lags behind data scale. By integrating Human Activity Knowledge (HAKE) with Object Affordances, we have developed a systematic task-design framework that focuses on identifying and evaluating a robot's ability to handle diverse, long-tail, and complex interaction tasks. Through this effort, we aim to provide a more comprehensive assessment of embodied agents and encourage the development of increasingly sophisticated and diverse robotic datasets.

As the inaugural milestone toward a "Robot Learning Olympics," we have released **GM-100**. This benchmark comprises 100 meticulously curated tasks covering extensive long-tail behaviors, supported by over 13,000 expert trajectories collected across multiple robotic platforms. GM-X serves as a foundational ecosystem, fostering a transparent and collaborative environment to push the boundaries of general-purpose robotic intelligence.

## üì¢ News
- **[2026-02-03]** [Task Object Purchase Links](https://docs.google.com/spreadsheets/d/1iUWwBSBhfWMjdNOwm4OGQbNpg-Qmwblp/edit?usp=sharing&ouid=111542188496207675206&rtpof=true&sd=true) are now available on the Project Page.
- **[2026-01-18]** Preview version of the Project Page is live! Check it out [here](https://www.rhos.ai/research/gm-100).
- **[2026-01-16]** GM-100 Paper released on arXiv.

## üì¶ Dataset
The GM-100 dataset is publicly available for research purposes. You can access and download the dataset from our [Hugging Face page](https://huggingface.co/rhos-ai).  
| Platform | Lerobot | HDF5 | 
| :---: | :---: | :---: |
| Agilex Cobot Magic | [Download](https://huggingface.co/datasets/rhos-ai/gm100-cobotmagic-lerobot) | / |
| Dobot Xtrainer | Processing... | [Download](https://huggingface.co/datasets/rhos-ai/gm100-xtrainer) |
| More Platforms on the Way | Stay Tuned! | Stay Tuned! |


## ü§ù Community & Contact
For general discussions, questions, or sharing your work related to GM-X, feel free to join our WeChat or Feishu groups by scanning the QR codes below.

For submissions of new evaluation, datasets, or collaborations, please follow the instructions in Project Page and reach out to us via email at `rhos.ai@outlook.com`.

**Join our Community:**
Feel free to submit issues if QR codes are not accessible.

| WeChat | Feishu |
| :---: | :---: |
| ![WeChat QR](assets/Wechat.jpg) | ![Feishu QR](assets/Feishu.JPG) |

##  citation
If you find our work useful in your research, please consider citing:

```bibtex
@misc{wang2026greatmarch100100,
      title={The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents}, 
      author={Ziyu Wang and Chenyuan Liu and Yushun Xiang and Runhao Zhang and Qingbo Hao and Hongliang Lu and Houyu Chen and Zhizhong Feng and Kaiyue Zheng and Dehao Ye and Xianchao Zeng and Xinyu Zhou and Boran Wen and Jiaxin Li and Mingyu Zhang and Kecheng Zheng and Qian Zhu and Ran Cheng and Yong-Lu Li},
      year={2026},
      eprint={2601.11421},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2601.11421}, 
}
```
